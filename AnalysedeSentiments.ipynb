{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bb9444a2-ea8b-461f-9c4a-3f50cadf6c73"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; _Éducation sentimentale_\n",
    "<br />\n",
    "## Analyse de sentiments de critiques cinématographiques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2e59aaa6-0f62-44b2-9cd4-3d938804f9b8"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <a>www.imdb.com</a>\n",
    "<br />\n",
    "<img src=\"review.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "58b1b34d-6929-47f4-a53f-a58d879fc69e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Analyse de sentiments, ça sert à quoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1ed88077-9550-4efd-b1d3-bfbdb66d1570"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Beaucoup de données textuelles ne sont pas labélisées ...\n",
    "\n",
    "- les tweets\n",
    "- les posts de blog\n",
    "- les e-mails\n",
    "- les tickets de support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8369836e-8939-48fa-a49a-f5685bc87bcf"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les données\n",
    "\n",
    "- corpus de 50.000 critiques catégorisées (25.000 critiques d'apprentissage, 25.000 critiques de test)\n",
    "- téléchargées de http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- utilisées dans: Maas et al. (2011). Learning Word Vectors for Sentiment Analysis (http://www.aclweb.org/anthology/P11-1015)\n",
    "- prétraitement comme décrit dans https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3b51509a-fa71-4655-8846-7004f69ecc8c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Charger les données prétraitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9b412181-a53c-4002-bb62-1d423d07b9d5"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with io.open('data/aclImdb/train-pos.txt', encoding='utf-8') as f:\n",
    "    train_pos = pd.DataFrame({'review': list(f)})    \n",
    "with io.open('data/aclImdb/train-neg.txt', encoding='utf-8') as f:\n",
    "    train_neg = pd.DataFrame({'review': list(f)}) \n",
    "train_reviews = pd.concat([train_neg, train_pos], ignore_index=True)\n",
    "\n",
    "with io.open('data/aclImdb/test-pos.txt', encoding='utf-8') as f:\n",
    "    test_pos = pd.DataFrame({'review': list(f)})\n",
    "with io.open('data/aclImdb/test-neg.txt', encoding='utf-8') as f:\n",
    "    test_neg = pd.DataFrame({'review': list(f)})    \n",
    "test_reviews = pd.concat([test_neg, test_pos], ignore_index=True)\n",
    "  \n",
    "X_train = train_reviews['review']\n",
    "X_test = test_reviews['review']\n",
    "\n",
    "y_train = np.append(np.zeros(12500), np.ones(12500))\n",
    "y_test = np.append(np.zeros(12500), np.ones(12500)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2050416b-8329-4dc5-a569-4b3b7ad1c511"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1ère critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eb900290-dbff-4b65-8485-963d6ea9ef37"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"a reasonable effort is summary for this film .  a good sixties film but lacking any sense of achievement .  maggie smith gave a decent performance which was believable enough but not as good as she could have given ,  other actors were just dreadful !  a terrible portrayal .  it wasn't very funny and so it didn't really achieve its genres as it wasn't particularly funny and it wasn't dramatic .  the only genre achieved to a satisfactory level was romance .  target audiences were not hit and the movie sent out confusing messages .  a very basic plot and a very basic storyline were not pulled off or performed at all well and people were left confused as to why the film wasn't as good and who the target audiences were etc .  however maggie was quite good and the storyline was alright with moments of capability .   4 . \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a6731c74-7b42-4f60-ab97-0b45f9e01376"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Positif? Négatif?\n",
    "\n",
    "Qu'en ont pensé les annotateurs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1508f8a0-0168-4832-9053-e9f2144e8ef1"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cf4e4aa1-9e9d-4200-ba09-288dcd904f34"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Une approche naïve: sac de mots (bag-of-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "63722553-a189-435d-8517-2a1c54f9e0c2"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sac de mots, en un mot\n",
    "\n",
    "- calculer la somme pondérée des mots positifs\n",
    "- calculer la somme pondérée des mots négatifs\n",
    "- le plus grand score gagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7bd1fc65-6812-4230-a7de-af6fa69d3290"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Personne ne va consacrer le reste de ses jours à la catégorisation de tous ces mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8eaa90b3-1520-4ecc-979a-ee109c789e42"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faut-il de la magie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "134b2fb8-8ebf-4f71-911a-f345c75879ec"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pas encore.\n",
    "\n",
    "On a le corpus d'apprentissage où les critiques ont été catégorisées comme positives ou négatives:\n",
    "\n",
    "<table border=\"1\">\n",
    "<tr>\n",
    "<th></th><th>sentiment</th><th>beautiful</th><th>bad</th><th>awful</th><th>decent</th><th>horrible</th><th>ok</th><th>awesome</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>review 1</th><td>0</td><td>0</td><td>1</td><td>2</td><td>1</td><td>1</td><td>0</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>review 2</th><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>review 3</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "157e3e5f-db82-4253-8468-de5c9105ce45"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification\n",
    "\n",
    "Utilisant le corpus d'apprentissage, on peut employer des méthodes de machine learning pour déterminer les polarités et les poids.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>word</th>\n",
    "<td>beautiful</td><td>bad</td><td>awful</td><td>decent</td><td>horrible</td><td>ok</td><td>awesome</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>weight</th>\n",
    "<td>3.4</td><td>-2.9</td><td>-5.6</td><td>-0.2</td><td>-4.9</td><td>-0.1</td><td>5.2</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5a30c4c5-0156-425a-b9b6-8976a5a1840e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bien.\n",
    "Mais ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3240cb82-cb6e-4fae-841a-68ca8d731f0b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Il y a un autre problème.\n",
    "\n",
    "Extraits de la toute première critique, citée avant:\n",
    "\n",
    "> performance which was believable enough but not as good as she could have given\n",
    "\n",
    "> lacking any sense of achievement \n",
    "\n",
    "> it wasn't very funny\n",
    "\n",
    "> the only genre achieved to a satisfactory level was romance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "57e6f868-97e4-4631-89dd-5fc6bf4e60fe"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ce qui est important, c'est le contexte.\n",
    "\n",
    "funny             =>    +\n",
    "\n",
    "very funny        =>    ++\n",
    "\n",
    "wasn't unbelievably funny =>    -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d82e034c-660f-4c01-a0f4-2ca6af09f39e"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... ou même\n",
    "- \"wasn't utterly unbelievably funny\"\n",
    "- \"however, I wouldn't say that it wasn't utterly unbelievably funny\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d1a73e37-d8df-41e0-bfd2-a8a0f6d55112"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unigrammes, bigrammes, trigrammes ... qu'est-ce qu'il faut regarder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3f71e5d9-186e-42be-b103-43b37f8cc2eb"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Au lieu de deviner, allons voir ce qui va  le mieux avec notre corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ab46562b-9215-4c76-aa5e-1422491f0058"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unigrammes plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "072eddd5-a2be-4155-b058-518f42407b75"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44047</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42623</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40159</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30632</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26795</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20281</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15147</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14067</td>\n",
       "      <td>very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12727</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12716</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   word\n",
       "0  44047  movie\n",
       "1  42623    but\n",
       "2  40159   film\n",
       "3  30632    not\n",
       "4  26795    one\n",
       "5  20281   like\n",
       "6  15147   good\n",
       "7  14067   very\n",
       "8  12727   time\n",
       "9  12716     no"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_1gram = pd.read_csv('word_counts_sorted_ngram_1_stopwords_removed.csv', \n",
    "                                  usecols=['word', 'count'])\n",
    "word_count_1gram.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "75680ac2-cf07-4b68-8fca-db02c70bab2f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bigrammes plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3776faee-8f3f-4096-89cd-3ee43abb1f13"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1925</td>\n",
       "      <td>but not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1321</td>\n",
       "      <td>ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1284</td>\n",
       "      <td>not only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1113</td>\n",
       "      <td>special effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1043</td>\n",
       "      <td>even though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1032</td>\n",
       "      <td>movie but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1024</td>\n",
       "      <td>don know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1007</td>\n",
       "      <td>movie not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>888</td>\n",
       "      <td>one best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count             word\n",
       "0   1925          but not\n",
       "1   1321        ever seen\n",
       "2   1284         not only\n",
       "3   1200        very good\n",
       "4   1113  special effects\n",
       "5   1043      even though\n",
       "6   1032        movie but\n",
       "7   1024         don know\n",
       "8   1007        movie not\n",
       "9    888         one best"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_2grams = pd.read_csv('word_counts_sorted_ngram_2_stopwords_removed.csv', \n",
    "                                  usecols=['word', 'count'])\n",
    "word_count_2grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "05875104-1025-49ea-93c5-4c588972a331"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trigrammes plus fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "55ff6123-eb9e-40e2-bff8-8cfe5b79107c"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262</td>\n",
       "      <td>movie ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243</td>\n",
       "      <td>worst movie ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>205</td>\n",
       "      <td>don waste time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>movies ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164</td>\n",
       "      <td>new york city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162</td>\n",
       "      <td>don get wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>160</td>\n",
       "      <td>one worst movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>141</td>\n",
       "      <td>worst movies ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120</td>\n",
       "      <td>film ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114</td>\n",
       "      <td>movie ever made</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count               word\n",
       "0    262    movie ever seen\n",
       "1    243   worst movie ever\n",
       "2    205     don waste time\n",
       "3    177   movies ever seen\n",
       "4    164      new york city\n",
       "5    162      don get wrong\n",
       "6    160   one worst movies\n",
       "7    141  worst movies ever\n",
       "8    120     film ever seen\n",
       "9    114    movie ever made"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_3grams = pd.read_csv('word_counts_sorted_ngram_3_stopwords_removed.csv', \n",
    "                                  usecols=['word', 'count'])\n",
    "word_count_3grams.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a27f047-f822-4db4-bc16-fea7babcff95"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# À la recherche de la meilleure combinaison (grid search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "69909e4d-8ac7-4634-95ea-c3efd1d11b52"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Quel classifieur fonctionne le mieux?\n",
    "- Régression logistique? Forêts aléatoires? Machines à vecteurs de support?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "20aa93d6-5c84-40c6-a47e-4c6c5c0ac409"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Combiné avec quel genre de données?\n",
    "- Unigrammes? Bigrammes? Trigrammes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "847c4e43-3a0b-4377-9c2b-e74ae2ae71b0"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choisissant comment les hyperparamètres\n",
    "- comme par example, régularisation, nombre d'itérations...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "75ddc951-43fd-4d06-90e1-7c70d3c1dba8"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;QUELQUES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "935088d8-4054-4991-9f13-45d2f8ceb843"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HEURES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "54553cb2-085f-48bc-a2eb-5879c664171e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PLUS   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f3383604-0580-4e29-8692-23c607aa73f8"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TARD  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2dd5ccea-3302-4f85-9788-3c2d5c7941e7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Et le gagnant est ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3c5573bd-c7f8-485a-9fd1-fea42b7c41a4"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Meilleure précision par classifieur (données de test)\n",
    "<table border=\"1\">\n",
    "<tr><th></th><th>1-grams<br />with stopword filtering</th><th>1-2-grams<br />with stopword filtering</th><th>1-3-grams<br />no stopword filtering</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Logistic Regression</th><td></td><td>0.89</td><td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Support Vector Machine</th><td></td><td></td><td>0.84</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Random Forest</th><td>0.84</td><td></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "77df1c97-0fbe-4583-9551-228768054b4c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Donc ... le meilleur classifieur comment fonctionne-t-il?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "37819f79-1aab-40e8-ad6a-e7888e3a627f"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.03, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stopwords_nltk = set(stopwords.words(\"english\"))\n",
    "relevant_words = set(['not', 'nor', 'no', 'wasn', 'ain', 'aren', 'very', 'only', 'but', 'don', 'isn', 'weren'])\n",
    "stopwords_filtered = list(stopwords_nltk.difference(relevant_words))\n",
    "vectorizer = CountVectorizer(stop_words =  stopwords_filtered, max_features = 10000, ngram_range = (1,2))\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "\n",
    "logistic_model = LogisticRegression(C=0.03) \n",
    "logistic_model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "558b19f1-1c6c-4660-a60a-2112eb741892"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mots plus positifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "81e05ff3-b44c-4960-8704-cd109590072e"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>0.672635</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6681</th>\n",
       "      <td>0.563958</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9816</th>\n",
       "      <td>0.521026</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8646</th>\n",
       "      <td>0.520818</td>\n",
       "      <td>superb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.505146</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.502118</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>0.481505</td>\n",
       "      <td>must see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>0.461807</td>\n",
       "      <td>loved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>0.458645</td>\n",
       "      <td>funniest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>0.453481</td>\n",
       "      <td>enjoyable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef       word\n",
       "2969  0.672635  excellent\n",
       "6681  0.563958    perfect\n",
       "9816  0.521026  wonderful\n",
       "8646  0.520818     superb\n",
       "3165  0.505146   favorite\n",
       "431   0.502118    amazing\n",
       "5923  0.481505   must see\n",
       "5214  0.461807      loved\n",
       "3632  0.458645   funniest\n",
       "2798  0.453481  enjoyable"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names()\n",
    "coefs = logistic_model.coef_\n",
    "word_importances = pd.DataFrame({'word': vocabulary, 'coef': coefs.tolist()[0]})\n",
    "word_importances_sorted = word_importances.sort_values(by='coef', ascending = False)\n",
    "word_importances_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a81b4ba-1818-4db7-8072-6104306ee1eb"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mots plus négatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cbd53924-3d10-4b27-8a2b-118a8176fbb9"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>-0.564446</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>-0.565503</td>\n",
       "      <td>dull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9855</th>\n",
       "      <td>-0.575060</td>\n",
       "      <td>worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>-0.588133</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>-0.596302</td>\n",
       "      <td>disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>-0.675187</td>\n",
       "      <td>poorly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>-0.681608</td>\n",
       "      <td>boring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>-0.688024</td>\n",
       "      <td>disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>-0.811184</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>-0.838195</td>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef            word\n",
       "6864 -0.564446            poor\n",
       "2625 -0.565503            dull\n",
       "9855 -0.575060           worse\n",
       "4267 -0.588133        horrible\n",
       "2439 -0.596302   disappointing\n",
       "6866 -0.675187          poorly\n",
       "1045 -0.681608          boring\n",
       "2440 -0.688024  disappointment\n",
       "702  -0.811184           awful\n",
       "9607 -0.838195           waste"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances_sorted[-11:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2b85ab93-9d66-4f32-b73b-1010b5ee9117"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spécial bigrammes: plus positifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d0f8aee9-31a9-4628-a30b-53d2a1dee167"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>0.481505</td>\n",
       "      <td>must see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450675</td>\n",
       "      <td>10 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>0.421314</td>\n",
       "      <td>one best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>0.389081</td>\n",
       "      <td>well worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5452</th>\n",
       "      <td>0.371277</td>\n",
       "      <td>may not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>0.329485</td>\n",
       "      <td>not bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>0.323805</td>\n",
       "      <td>pretty good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>0.307238</td>\n",
       "      <td>definitely worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>0.303380</td>\n",
       "      <td>love movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9432</th>\n",
       "      <td>0.301404</td>\n",
       "      <td>very good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef              word\n",
       "5923  0.481505          must see\n",
       "3     0.450675             10 10\n",
       "6350  0.421314          one best\n",
       "9701  0.389081        well worth\n",
       "5452  0.371277           may not\n",
       "6139  0.329485           not bad\n",
       "6970  0.323805       pretty good\n",
       "2259  0.307238  definitely worth\n",
       "5208  0.303380        love movie\n",
       "9432  0.301404         very good"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances_bigrams = word_importances_sorted[word_importances_sorted.word.apply(lambda c: len(c.split()) >= 2)]\n",
    "word_importances_bigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "95c9b60d-46ea-4f42-99d6-41f3de053370"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spécial bigrammes: plus négatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ab9811af-52c5-4d9e-991b-be0d6b7da95f"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>-0.247169</td>\n",
       "      <td>only good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>-0.250090</td>\n",
       "      <td>fast forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>-0.264564</td>\n",
       "      <td>worst movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>-0.324169</td>\n",
       "      <td>not recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>-0.332796</td>\n",
       "      <td>not even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>-0.333147</td>\n",
       "      <td>not funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>-0.357056</td>\n",
       "      <td>not very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>-0.368976</td>\n",
       "      <td>not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>-0.437750</td>\n",
       "      <td>one worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>-0.451138</td>\n",
       "      <td>waste time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef           word\n",
       "6431 -0.247169      only good\n",
       "3151 -0.250090   fast forward\n",
       "9861 -0.264564    worst movie\n",
       "6201 -0.324169  not recommend\n",
       "6153 -0.332796       not even\n",
       "6164 -0.333147      not funny\n",
       "6217 -0.357056       not very\n",
       "6169 -0.368976       not good\n",
       "6421 -0.437750      one worst\n",
       "9609 -0.451138     waste time"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importances_bigrams[-11:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2b3981ad-d72b-4b3b-bc61-24b531057617"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Donc, une précision de 0.89 n'est pas mauvaise du tout\n",
    "<br />\n",
    "## Peut-on faire mieux?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "20971459-c03c-4214-a231-e98e1704a1ef"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Au-delà des sacs de mots ...\n",
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3ec7e812-285a-4bad-8648-ef163b96aef5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Essentiellement, le bag-of-words  (ou bag-of-ngrams) est basé sur l'encodage one-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "f1e86a43-24ca-4df5-91cf-3551812f2d00"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alike</th>\n",
       "      <th>all</th>\n",
       "      <th>but</th>\n",
       "      <th>dataset</th>\n",
       "      <th>every</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>its</th>\n",
       "      <th>messy</th>\n",
       "      <th>own</th>\n",
       "      <th>tidy</th>\n",
       "      <th>way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alike  all  but  dataset  every  in  is  its  messy  own  tidy  way\n",
       "0       0    0    0        0      0   0   0    0      0    0     1    0\n",
       "1       0    0    0        1      0   0   0    0      0    0     0    0\n",
       "2       0    0    0        0      0   0   1    0      0    0     0    0\n",
       "3       0    1    0        0      0   0   0    0      0    0     0    0\n",
       "4       1    0    0        0      0   0   0    0      0    0     0    0\n",
       "5       0    0    1        0      0   0   0    0      0    0     0    0\n",
       "6       0    0    0        0      1   0   0    0      0    0     0    0\n",
       "7       0    0    0        0      0   0   0    0      1    0     0    0\n",
       "8       0    0    0        0      0   1   0    0      0    0     0    0\n",
       "9       0    0    0        0      0   0   0    1      0    0     0    0\n",
       "10      0    0    0        0      0   0   0    0      0    1     0    0\n",
       "11      0    0    0        0      0   0   0    0      0    0     0    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tidy datasets are all alike but every messy dataset is messy in its own way.\n",
    "words = pd.DataFrame({'tidy': [1,0,0,0,0,0,0,0,0,0,0,0], 'dataset': [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "                      'is': [0,0,1,0,0,0,0,0,0,0,0,0], 'all': [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "                      'alike': [0,0,0,0,1,0,0,0,0,0,0,0], 'but': [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "                      'every': [0,0,0,0,0,0,1,0,0,0,0,0], 'messy': [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "                      'in': [0,0,0,0,0,0,0,0,1,0,0,0], 'its': [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "                      'own': [0,0,0,0,0,0,0,0,0,0,1,0], 'way': [0,0,0,0,0,0,0,0,0,0,0,1]})\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b58c3405-9769-4d45-90d3-f807d5511651"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dans ce modèle, tous les mots sont équidistants l'un de l'autre.\n",
    "<br />\n",
    "## Comment découvrir des mots sémantiquement proches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c7111cbd-097d-4d8c-8f3a-f25f84d1f834"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pour découvrir les proximités sémantiques, faut\n",
    "\n",
    "- construire une matrice de co-occurrence\n",
    "- appliquer une technique de <b>réduction de dimension</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "312cc255-fbe7-4b64-9e24-79915f12f671"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrice de co-occurrence \n",
    "\"Tidy datasets are all alike but every messy dataset is messy in its own way.\" (Hadley Wickham)\n",
    "\n",
    "\"Happy families are all alike; every unhappy family is unhappy in its own way.\" (Lev Tolstoj)\n",
    "\n",
    "<br />\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td></td><th>tidy</th><th>dataset</th><th>is</th><th>all</th><th>alike</th><th>but</th><th>every</th><th>messy</th><th>in</th><th>its</th><th>own</th><th>way</th><th>happy</th><th>family</th><th>unhappy</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>tidy</th><td>0</td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>dataset</th><td>2</td><td>0</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>is</th><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[and so on]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f0bbeed3-3481-42be-b48f-fff2fbf190b8"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En réalité, cette approche est peu pratique. Entre ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7921c135-97a6-430b-8305-2af7430b79ae"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word embeddings - l'approche réseaux de neurones\n",
    "Inférer la signification d'un mot de son contexte\n",
    "\n",
    "- prédisant la probabilité d'occurrence d'un mot d'après son contexte \n",
    "- améliorer la prédiction à chaque itération (backprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2d6184f0-e520-4c7b-8c9e-a92575b26393"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Représentations distribuées (Distributed Representations)\n",
    "\n",
    "- chaque mot est représenté non pas par un seul bit qui est \"on\", mais par un vecteur de nombres réels\n",
    "- Ce qui nous permet de trouver des proximités sémantiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ea0826b9-5ce4-4b04-bf78-f8b77b99dc20"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## word2vec\n",
    "\n",
    "Mikolov et al (2013a).  Efficient estimation of word representations in vector space. arXiv:1301.3781.\n",
    "\n",
    "- Continuous Bag of Words (CBOW)\n",
    "- Skip-Gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "672bf651-2673-4c90-a62a-d1d638f9dc24"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous Bag of Words \n",
    "\n",
    "<img src='cbow.png'>\n",
    "dans: Mikolov et al. 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a6ac9fdb-022f-4609-9212-490b3588a037"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skip-gram\n",
    "\n",
    "<img src='skip_gram.png'>\n",
    "dans: Mikolov et al. 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bcc44545-57d0-4e4a-96f2-4834a8232436"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relations\n",
    "\n",
    "<img src='relationships.png'>\n",
    "\n",
    "dans: Mikolov et al. 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "19be52fc-04ce-47b7-9523-dc5b6ed72c9c"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\"Athens\" - \"Greece\" + \"Norway\" = ?\n",
    "\n",
    "\"walking\" - \"walked\" + \"swam\" = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6b398bf9-b9a5-4b23-b256-436960b8ec61"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word embeddings pour les données IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ceb866c7-9d11-4c23-a676-6229ba5b7625"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# word2vec en Python\n",
    "\n",
    "- implementation efficace dans la librairie gensim : <i>https://radimrehurek.com/gensim/models/word2vec.html</i>\n",
    "- bon tutoriel: <i>https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8acddef5-52e8-4807-90ce-d2c3d180f7b6"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Allons charger le modèle pré-entrâiné ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "943bc95f-90ac-46fb-a6dd-c39aa97c73e8"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20166, 100)\n",
      "[-0.02515472  0.16707493 -0.05629794 -0.12409752 -0.01091802 -0.13798206\n",
      "  0.09231102 -0.09140468 -0.05452388 -0.03555677 -0.08269091 -0.00567267\n",
      " -0.09523809 -0.06195637  0.05440474  0.06227686  0.12369317 -0.01537143\n",
      " -0.0089783  -0.00528997 -0.04277094  0.07739993 -0.01932896  0.081738\n",
      " -0.22357117 -0.14976217  0.05551976  0.13742755 -0.15443996 -0.05471482\n",
      " -0.0009601   0.08932991 -0.05292547  0.16765165 -0.05905993 -0.05231098\n",
      " -0.08250861 -0.0341751   0.14372236  0.03478728 -0.01529499 -0.0296018\n",
      "  0.01079863 -0.06377127  0.04163288 -0.07192093  0.25450262 -0.07382536\n",
      " -0.07778623  0.07499653 -0.12951691  0.01970425  0.13499822  0.01038768\n",
      "  0.06625408  0.11575779  0.10367264  0.03894637 -0.07102726  0.00343542\n",
      "  0.24314043  0.15759529 -0.09808595  0.04601007 -0.01187227 -0.16023833\n",
      " -0.17658544 -0.12622575 -0.04592994  0.08045016 -0.11856512  0.04920706\n",
      "  0.20129348  0.08923753 -0.06545419 -0.05853761 -0.08146987 -0.06782326\n",
      "  0.17082241  0.02575272  0.058911    0.13305175 -0.12224633 -0.01143302\n",
      "  0.01318115  0.07662909 -0.09469278 -0.05230315 -0.0121863   0.12192696\n",
      "  0.19957212 -0.075518    0.16371782 -0.07655586 -0.09539564  0.11822125\n",
      "  0.04177237  0.11499111 -0.09205962  0.09952193]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "# load the trained model from disk\n",
    "model = word2vec.Word2Vec.load('models/word2vec_100features')\n",
    "print(model.syn0.shape)\n",
    "print(model['movie'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cbc9ae78-d50e-4377-9231-6a8d708d75d3"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quels sont les mots similaires à <i>awesome</i>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'amazing', 0.7929322123527527),\n",
       " (u'incredible', 0.7127916812896729),\n",
       " (u'awful', 0.7072071433067322),\n",
       " (u'excellent', 0.6961393356323242),\n",
       " (u'fantastic', 0.6925109624862671),\n",
       " (u'alright', 0.6886886358261108),\n",
       " (u'cool', 0.679090142250061),\n",
       " (u'outstanding', 0.6213874816894531),\n",
       " (u'astounding', 0.613292932510376),\n",
       " (u'terrific', 0.6013768911361694)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('awesome', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ... et à <i> awful</i>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.8212785124778748),\n",
       " (u'horrible', 0.7955455183982849),\n",
       " (u'atrocious', 0.7824822664260864),\n",
       " (u'dreadful', 0.7722172737121582),\n",
       " (u'appalling', 0.7244443893432617),\n",
       " (u'horrendous', 0.7235419154167175),\n",
       " (u'abysmal', 0.720653235912323),\n",
       " (u'amazing', 0.708114743232727),\n",
       " (u'awesome', 0.7072070837020874),\n",
       " (u'bad', 0.6963905096054077)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('awful', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Peut-on soustraire <i>awful</i>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'jolly', 0.3947059214115143),\n",
       " (u'midget', 0.38988131284713745),\n",
       " (u'knight', 0.3789686858654022),\n",
       " (u'spooky', 0.36937469244003296),\n",
       " (u'nice', 0.3680706322193146),\n",
       " (u'looney', 0.3676275610923767),\n",
       " (u'ho', 0.3594890832901001),\n",
       " (u'gotham', 0.35877227783203125),\n",
       " (u'lookalike', 0.3579031229019165),\n",
       " (u'devilish', 0.35554438829421997)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['awesome'], negative=['awful'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Essayons aussi avec <i>good</i> - <i>bad</i>: <i>Good</i> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'bad', 0.769078254699707),\n",
       " (u'decent', 0.7574324607849121),\n",
       " (u'great', 0.7527369260787964),\n",
       " (u'nice', 0.6981208324432373),\n",
       " (u'cool', 0.653165340423584),\n",
       " (u'fine', 0.6289849877357483),\n",
       " (u'terrific', 0.6136247515678406),\n",
       " (u'terrible', 0.6056008338928223),\n",
       " (u'fantastic', 0.596002995967865),\n",
       " (u'solid', 0.5957943201065063)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('good', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ... et <i>bad</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'good', 0.769078254699707),\n",
       " (u'terrible', 0.7315745949745178),\n",
       " (u'horrible', 0.7259382009506226),\n",
       " (u'awful', 0.6963905096054077),\n",
       " (u'lame', 0.6728411912918091),\n",
       " (u'stupid', 0.6556650996208191),\n",
       " (u'dumb', 0.628576934337616),\n",
       " (u'lousy', 0.6129568815231323),\n",
       " (u'cheesy', 0.6102402210235596),\n",
       " (u'poor', 0.5851123929023743)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('bad', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Donc <i>good</i> moins <i>bad</i> c'est ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'nice', 0.4700997471809387),\n",
       " (u'fine', 0.46652451157569885),\n",
       " (u'solid', 0.43668174743652344),\n",
       " (u'wonderful', 0.4121875464916229),\n",
       " (u'pleasant', 0.4049694538116455),\n",
       " (u'decent', 0.3975681960582733),\n",
       " (u'commendable', 0.39051422476768494),\n",
       " (u'splendid', 0.38586685061454773),\n",
       " (u'promising', 0.38155609369277954),\n",
       " (u'delightful', 0.38095542788505554)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['good'], negative=['bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quel mot ne convient pas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"good bad awful terrible\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awesome'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"awesome bad awful terrible\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excellent'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"nice pleasant fine excellent\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quoi alors de notre tâche de classification?\n",
    "\n",
    "- on a un vecteur par mot\n",
    "- il faut un vecteur par critique\n",
    "- ce qu'on peut faire: prendre la moyenne\n",
    "- mais comme ça on va <i>perdre de l'information</i>!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# word2vec: précision classificatoire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Meilleure précision par classifieur\n",
    "<table border=\"1\">\n",
    "<tr>\n",
    "<th></th><th>Bag of words</th><th>word2vec</th>\n",
    "<tr>\n",
    "<th>Logistic Regression</th><td>0.89</td><td>0.83</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Support Vector Machine</th><td>0.84</td><td>0.70</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Random Forest</th><td>0.84</td><td>0.80</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Avec word2vec, on perd de l'information\n",
    "\n",
    "- faut prendre la moyenne des vecteurs de mots pour obtenir un vecteur \"de paragraphe\"\n",
    "- contexte du paragraphe est perdu (intentionnellement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Et si on avait de vrais vecteurs de paragraphe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vecteurs de paragraphe: doc2vec\n",
    "\n",
    "Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. In International\n",
    "Conference on Machine Learning, 2014.\n",
    "\n",
    "\n",
    "- Distributed Memory Model of Paragraph Vectors (PV-DM)\n",
    "  - le vecteur de paragraphe fait partie de la moyenne avec les autres vecteurs (de mots)\n",
    "  - le vecteur de paragraphe peut être entré directement dans un classifieur d'apprentissage automatique\n",
    "  <br /><br />\n",
    "- Distributed Bag of Words (PV-DBOW)\n",
    "  - les mots du contexte sont ignorés tout à fait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed Memory Model of Paragraph Vectors (PV-DM)\n",
    "\n",
    "<img src='pv_dm.png'>\n",
    "\n",
    "Dans: Q. V. Le and T. Mikolov. Distributed representations of sentences and documents. In International\n",
    "Conference on Machine Learning, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# doc2vec en Python:\n",
    "\n",
    "- comme word2vec, implementé dans gensim <i>https://radimrehurek.com/gensim/models/doc2vec.html</i>\n",
    "- pour l'usage et la configuration, voir le tutoriel gensim doc2vec (<i>https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Charger les modèles pré-entrâinés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "models_dir = 'models'\n",
    "filenames = ['dmc', 'cbow', 'dmm']\n",
    "files = map(lambda f:'/'.join([models_dir,f]), filenames)\n",
    "models = [Doc2Vec.load(fname) for fname in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doc2Vec(dm/c,d100,n5,w5,mc2,t4)',\n",
       " 'Doc2Vec(dbow,d100,n5,mc2,t4)',\n",
       " 'Doc2Vec(dm/m,d100,n5,w10,mc2,t4)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(model) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Précision de classification (régression logistique)\n",
    "<table border=\"1\">\n",
    "<tr>\n",
    "<th></th><th>test vectors inferred</th><th>test vectors from model</th>\n",
    "<tr>\n",
    "<th>Distributed memory, vectors averaged (dm/m)</th><td>0.81</td><td>0.87</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Distributed memory, vectors concatenated (dm/c)</th><td>0.80</td><td>0.82</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Distributed bag of words (dbow)</th><td>0.90</td><td>0.90</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plus similaire à <i>awesome</i> - qu'est-ce que dit notre modèle plus performant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'juon', 0.3789939880371094),\n",
       " (u'a-pix', 0.3781469762325287),\n",
       " (u\"rosemary's\", 0.37472963333129883),\n",
       " (u'schnook', 0.3683214783668518),\n",
       " (u\"luise's\", 0.366854190826416),\n",
       " (u'chrysalis', 0.36428096890449524),\n",
       " (u'f*^', 0.362865686416626),\n",
       " (u'decadent', 0.3604990839958191),\n",
       " (u'surrogacy', 0.35499149560928345),\n",
       " (u\"'second\", 0.35283005237579346)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbow = models[1]\n",
    "dbow.most_similar('awesome', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Distributed bag of words n'entrâine pas de vecteurs de mots ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plus similaire à <i>awesome</i> - distributed memory model (dm/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'amazing', 0.9163687229156494),\n",
       " (u'incredible', 0.9011116027832031),\n",
       " (u'excellent', 0.8860622644424438),\n",
       " (u'outstanding', 0.8797732591629028),\n",
       " (u'exceptional', 0.8539372682571411),\n",
       " (u'awful', 0.8104138970375061),\n",
       " (u'astounding', 0.7750493884086609),\n",
       " (u'alright', 0.7587056159973145),\n",
       " (u'astonishing', 0.7556235790252686),\n",
       " (u'extraordinary', 0.743841290473938)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_m = models[2]\n",
    "dm_m.most_similar('awesome', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plus similaire à <i>awful</i> - distributed memory model (dm/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'abysmal', 0.8371909856796265),\n",
       " (u'appalling', 0.8327066898345947),\n",
       " (u'atrocious', 0.8309577703475952),\n",
       " (u'horrible', 0.8192445039749146),\n",
       " (u'terrible', 0.8124841451644897),\n",
       " (u'awesome', 0.8104138970375061),\n",
       " (u'dreadful', 0.8072893023490906),\n",
       " (u'horrendous', 0.7981990575790405),\n",
       " (u'amazing', 0.7926105260848999),\n",
       " (u'incredible', 0.7852109670639038)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_m.most_similar('awful', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# On pourrait continuer à explorer comme ça pour toujours mais ...\n",
    "\n",
    "## ... conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Restez à l'écoute!\n",
    "\n",
    "Dans ce sujet, il se passe qc de captivant au moins chaque année...\n",
    "\n",
    "- 2013: word2vec (Google)\n",
    "- 2014: doc2vec (Google)\n",
    "- août 2016: fastText (Facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2017: ??? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "à poursuivre ... merci beaucoup de votre attention!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nbpresent": {
   "slides": {
    "f9d5349b-894e-40ac-a2c3-03a3fdbab349": {
     "id": "f9d5349b-894e-40ac-a2c3-03a3fdbab349",
     "prev": null,
     "regions": {
      "4d92a624-180f-4c5e-b31a-047948b7186e": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.1,
        "y": 0.7
       },
       "id": "4d92a624-180f-4c5e-b31a-047948b7186e"
      },
      "9c9f4d6b-ad92-44b0-977a-977faf1e308b": {
       "attrs": {
        "height": 0.6,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "bb9444a2-ea8b-461f-9c4a-3f50cadf6c73",
        "part": "source"
       },
       "id": "9c9f4d6b-ad92-44b0-977a-977faf1e308b"
      },
      "9fcbcabe-843e-46ae-904f-ed3f417d3df4": {
       "attrs": {
        "height": 0.2,
        "width": 0.4,
        "x": 0.5,
        "y": 0.7
       },
       "id": "9fcbcabe-843e-46ae-904f-ed3f417d3df4"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
